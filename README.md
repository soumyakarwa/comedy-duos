Data

Data is divided into scraping, cleaning and analysis.

// SCRAPING
In scraping, I have two scripts: wikiFandomScrapy.py and wikipediaScrapy.py.
wikiFandomScrapy scrapes from the Brooklyn Nine-Nine Wiki Fandom webpage and adds the output in brooklynNineNineEpisodeDescriptions.csv.
wikipediaScrapy scrapes from each Brooklyn Nine-Nine Wikipedia Season webpage and adds the output in brooklynNineNineEpisodeDescriptions.csv.

// ANALYSIS

// CLEANING

// SHARED
All files in this folder are written by Professor Justin Bakse. I was part of a class "Javascript + OpenAI" during Spring 2024, which Prof. Bakse taught. He provided us these files to build programs using the OpenAI API.
